function solveMDP(p::multiFareDynamicPricingProblem)

    # Initialize state = (ticketsAvailable, t)
    ticketsAvailable = p.totalTickets
    t = 1

    # Initialize state and action spaces

    ğ–²_space = LinearIndices((0:p.totalTickets,1:p.timeHorizon))
    ğ–²_size = length(ğ–²_space)
    sCartesianIndex = CartesianIndex(findfirst(x->x==ticketsAvailable,0:p.totalTickets),findfirst(x->x==t,1:p.timeHorizon))
    sLinearIndex = LinearIndices(x)[s_index]

    ğ– _space = LinearIndices(zeros([length(p.fareClasses[f].actionSpace) for f in keys(p.fareClasses)]...))
    ğ– _size = length(ğ– _space)

    # Initialize Q and r
    Q = zeros(ğ–²_size, ğ– _size)
    r = 0

    # Choose action

    function chooseAction(p::multiFareDynamicPricingProblem, ğ– _space::LinearIndices, LinearIndex::Int, ğ–²_size::Int)
        Ïµ_gaussian      = rand(Normal(p.Ïµ, 0))
        aLinearIndex    = rand(Bernoulli(Ïµ_gaussian)) == 1 ? rand(1:ğ–²_size) : argmax(Q[sLinearIndex, :])
        aCartesianIndex = CartesianIndices(ğ– _space)[aLinearIndex]
        a               = Dict(f => p.fareClasses[f].actionSpace[aCartesianIndex[i]] for (i,f) in enumerate(keys(p.fareClasses)))
        return a, aLinearIndex
    end

    a, aLinearIndex = chooseAction(p, ğ– _space, sLinearIndex, ğ–²_size)

    # Loop in t

    for t = 1:p.timeHorizon

        ticketsSoldâ€²          = Dict(k => Set() for k in keys(p.fareClasses))
        customersWithPurchase = Dict(k => Set() for k in keys(p.fareClasses))

        for f in keys(p.fareClasses)
            _, ticketsSoldâ€²[f], _, customersWithPurchase[f] = generativeModel(problem, f, ticketsAvailable, t, a[f])
        end
        if sum([ticketsSoldâ€²[f] for f in keys(p.fareClasses)]) > ticketsAvailable
            # Filter customersWithPurchase so that its length is exactly equal to ticketsAvailable
            customersWithPurchase = shuffle(customersWithPurchase)[1:ticketsAvailable]
            #Update ticketsSoldâ€²
            ticketsSoldâ€² = ticketsAvailable
        end

        #  Process purchases
        for f in keys(p.fareClasses)
            setdiff!(customersWithoutTickets[f], customersWithPurchase[f])
            union!(  customersWithTickets[f],    customersWithPurchase[f])
        end

        # Calculate new state and reward
        ticketsAvailableâ€² = ticketsAvailable - sum([ticketsSoldâ€²[f] for f in keys(p.fareClasses)])
        tâ€² = t + 1
        r = sum([a[f]*ticketsSold[f] for f in keys(p.fareClasses)])

        # Choose next action
        sCartesianIndexâ€² = CartesianIndex(findfirst(x->x==ticketsAvailableâ€²,0:p.totalTickets),findfirst(x->x==tâ€²,1:p.timeHorizon))
        sLinearIndexâ€² = LinearIndices(x)[s_index]
        aâ€², aLinearIndexâ€² = chooseAction(p, ğ– _space, sLinearIndexâ€², ğ–²_size)

        # Implement the Sarsa update step
        Q[sLinearIndex,  aLinearIndex] += p.Î·*(r + p.Î³*Q[sLinearIndexâ€²,  aLinearIndexâ€²] - Q[sLinearIndex,  aLinearIndex])

        # Update state and action
        ticketsAvailable = ticketsAvailableâ€²
        t = tâ€²
        a = aâ€²

        if ticketsAvailableâ€² == 0
            break
        end
    end

    # Extract policy
    Ï€â‹† = argmax(Q, dims=2) # can replace with argmax(Q, dim=1), I think
    Ï€â‹† = [Ï€â‹†[s][2] for s in 1:ğ–²]
end
